{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c06c96",
   "metadata": {},
   "source": [
    "# <font face = \"optima\"> Sentiment Semantic Learning <font>\n",
    "@ Chen Jicheng  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24267435",
   "metadata": {},
   "source": [
    "## Data Acquisition and Storage  \n",
    "ps: the following is not the given dataset, but the given dataset wiould be used at last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f35178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b5b363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"D:/跟课系列/2023年春/深度学习/My_work/陈纪程-2020110621-assignment-final/sst2\"\n",
    "# if you haven't load the dataset, please run the following code:\n",
    "#  sst2_dataset = load_dataset(\"glue\",name=\"sst2\",cache_dir = save_path + \"/load\")\n",
    "#  sst2_dataset.save_to_disk(save_path)\n",
    "sst2_data = load_from_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc781b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': Dataset({\n",
      "    features: ['sentence', 'label', 'idx'],\n",
      "    num_rows: 1821\n",
      "}),\n",
      " 'train': Dataset({\n",
      "    features: ['sentence', 'label', 'idx'],\n",
      "    num_rows: 67349\n",
      "}),\n",
      " 'validation': Dataset({\n",
      "    features: ['sentence', 'label', 'idx'],\n",
      "    num_rows: 872\n",
      "})}\n"
     ]
    }
   ],
   "source": [
    "# stt2_data = sst2_data.shuffle()\n",
    "# 注:使用shuffle()后的各个模型效果都会变差,更不稳定\n",
    "pprint(sst2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18f26d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two examples from the dataset using slice operation: \n",
      "\n",
      "{'sentence': 'contains no wit , only labored gags ', 'label': 0, 'idx': 1}\n",
      "{'sentence': \"this film 's relationship to actual tension is the same as what christmas-tree flocking in a spray can is to actual snow : a poor -- if durable -- imitation .\", 'label': -1, 'idx': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Two examples from the dataset using slice operation: \\n\")\n",
    "print(sst2_data['train'][1])\n",
    "print(sst2_data['test'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3269ca",
   "metadata": {},
   "source": [
    "## Word to Vector, Sentence to Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "135473a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([ 1.1891e-01,  1.5255e-01, -8.2073e-02, -7.4144e-01,  7.5917e-01,\n",
      "       -4.8328e-01, -3.1009e-01,  5.1476e-01, -9.8708e-01,  6.1757e-04,\n",
      "       -1.5043e-01,  8.3770e-01, -1.0797e+00, -5.1460e-01,  1.3188e+00,\n",
      "        6.2007e-01,  1.3779e-01,  4.7108e-01, -7.2874e-02, -7.2675e-01,\n",
      "       -7.4116e-01,  7.5263e-01,  8.8180e-01,  2.9561e-01,  1.3548e+00,\n",
      "       -2.5701e+00, -1.3523e+00,  4.5880e-01,  1.0068e+00, -1.1856e+00,\n",
      "        3.4737e+00,  7.7898e-01, -7.2929e-01,  2.5102e-01, -2.6156e-01,\n",
      "       -3.4684e-01,  5.5841e-01,  7.5098e-01,  4.9830e-01, -2.6823e-01,\n",
      "       -2.7443e-03, -1.8298e-02, -2.8096e-01,  5.5318e-01,  3.7706e-02,\n",
      "        1.8555e-01, -1.5025e-01, -5.7512e-01, -2.6671e-01,  9.2121e-01],\n",
      "      dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import torchtext.vocab as vocab\n",
    "import numpy as np\n",
    "\n",
    "# 1. 打开模型文件并读取所有行\n",
    "# glove 为 torchtext库中的词向量模型,负责将词汇映射到高维空间中\n",
    "# 模型下载请运行代码: glove = vocab.GloVe(name='6B', dim=50, cache=glove_path)\n",
    "with open(save_path[0:-4]+\"glove/glove.6B.50d.txt\", 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 2. 将每一行转化为一个单词和其对应的词向量表示，并存储在一个字典中\n",
    "glove_dict = {}\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], dtype='float32')\n",
    "    glove_dict[word] = vector\n",
    "    \n",
    "# 3. 使用字典\n",
    "word = 'i'\n",
    "vector_example = glove_dict[word]\n",
    "pprint(vector_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b17245",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dict[\"unentertaining\"] = glove_dict[\"un\"] + glove_dict[\"entertaining\"]\n",
    "# The only word can not be easily transformed into vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d349cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                sentence  label\n",
      "idx                                                            \n",
      "0           hide new secretions from the parental units       0\n",
      "1                   contains no wit , only labored gags       0\n",
      "2      that loves its characters and communicates som...      1\n",
      "3      remains utterly satisfied to remain the same t...      0\n",
      "4      on the worst revenge-of-the-nerds clichés the ...      0\n",
      "...                                                  ...    ...\n",
      "67344                               a delightful comedy       1\n",
      "67345                   anguish , anger and frustration       0\n",
      "67346  at achieving the modest , crowd-pleasing goals...      1\n",
      "67347                                  a patient viewer       1\n",
      "67348  this new jangle of noise , mayhem and stupidit...      0\n",
      "\n",
      "[67349 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sst2_train = pd.DataFrame(sst2_data[\"train\"])\n",
    "sst2_train.set_index(['idx'], inplace = True)\n",
    "print(sst2_train)\n",
    "sst2_test = pd.DataFrame(sst2_data[\"test\"])\n",
    "sst2_test.set_index(['idx'], inplace = True)\n",
    "sst2_validation = pd.DataFrame(sst2_data[\"validation\"])\n",
    "sst2_validation.set_index(['idx'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94882f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length of sentence is:  56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 53 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_words = 0\n",
    "lengths = {}\n",
    "for data_frame in [sst2_train, sst2_test, sst2_validation]:\n",
    "    for i in range(data_frame.shape[0]):\n",
    "        nwords = data_frame[\"sentence\"][i].count(\" \") + 1\n",
    "        lengths[nwords] = lengths[nwords] + 1 if nwords in lengths.keys() else 1\n",
    "        if max_words < nwords:\n",
    "            max_words = nwords\n",
    "print(\"The max length of sentence is: \",max_words)\n",
    "plt.title(\"The frequency in length of training sentences\")\n",
    "plt.bar(lengths.keys(), [lengths[key] for key in lengths.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2de459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# 借用 bert 的子词切分器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82cfc616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "# 报错请运行本句: nltk.download('punkt', download_dir=save_path[0:-4] + \"tokenizer\")\n",
    "nltk.data.path.append(save_path[0:-4] + \"tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939f52c",
   "metadata": {},
   "source": [
    "#### <font size = 4 face = \"Cambria Math\">Generally using the glove_dict, but also use bert_tokenizer and stem_porter as assistances<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd92ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def sentence_picture(sentence, max_seq_len):\n",
    "    # return_type is numpy\n",
    "    st = re.split(\"\\s|-\",sentence)\n",
    "    if not all(st) in glove_dict.keys():\n",
    "        for i in range(len(st)):\n",
    "            word = st[i]\n",
    "            if not st[i] in glove_dict.keys():\n",
    "                if PorterStemmer().stem('word') in glove_dict.keys():\n",
    "                    st[i] = PorterStemmer().stem('word')\n",
    "                else:\n",
    "                    words = tokenizer.tokenize(word)\n",
    "                    st[i] = words\n",
    "        new_st = []\n",
    "        for words_word in st:\n",
    "            if type(words_word) == list:\n",
    "                for word in words_word:\n",
    "                    word = re.sub('#', '', word)\n",
    "                    new_st.append(word)\n",
    "            else:\n",
    "                new_st.append(words_word)\n",
    "        st = new_st.copy()\n",
    "    for i in range(len(st)):\n",
    "        word = st[i]\n",
    "        st[i] = glove_dict[word]\n",
    "    st = np.asarray(st)\n",
    "    if st.shape[0] > max_seq_len and max_seq_len <= st.shape[1]:\n",
    "        st = np.transpose(st)\n",
    "        st = PCA(n_components = max_seq_len).fit_transform(st)\n",
    "        st = np.transpose(st)\n",
    "    elif st.shape[0] > max_seq_len:\n",
    "        raise Exception(\"Condition not satisfied:0< n_components< min(样本数，特征数),PCA is unable to decompose.\")\n",
    "    return st\n",
    "    \n",
    "def zip_st_pics(data_frame, max_seq_len, rand_padding = True):\n",
    "    # return_type is tensor\n",
    "    if not type(data_frame) == pd.core.frame.DataFrame:\n",
    "        raise Exception(\"The function only cope with class: pandas.core.frame.DataFrame\")\n",
    "    st_pics = np.zeros([data_frame.shape[0],max_seq_len,50],dtype = np.float32)\n",
    "    for idx in range(data_frame.shape[0]):\n",
    "        st_pic = np.zeros([max_seq_len,50])\n",
    "        sentence = data_frame[\"sentence\"][idx]\n",
    "        st = sentence_picture(sentence, max_seq_len)\n",
    "        # 输出的句长已变为[2~max_seq_len]\n",
    "        word_num = st.shape[0]\n",
    "        if rand_padding:\n",
    "            np.random.seed()\n",
    "            index = np.random.randint(0,max_seq_len - word_num + 1)\n",
    "        else:\n",
    "            index = 0\n",
    "        st_pic[index : index + word_num][:] = st\n",
    "        st_pics[idx] = st_pic\n",
    "    return torch.from_numpy(st_pics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7636a4b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The real max length of unfloded-sentence is:  58\n",
      "The real length of first 10 sentences in train_set: [8, 8, 13, 9, 14, 11, 26, 3, 9, 14]\n"
     ]
    }
   ],
   "source": [
    "def tokenized_wordnums(dataset_list):\n",
    "    max_words = 0\n",
    "    lens_record = []\n",
    "    for data_frame in dataset_list:\n",
    "        len_stack = []\n",
    "        for i in range(data_frame.shape[0]):\n",
    "            st = sentence_picture(data_frame[\"sentence\"][i], 1e5)\n",
    "            nwords = st.shape[0]\n",
    "            len_stack.append(nwords)\n",
    "            if max_words < nwords:\n",
    "                max_words = nwords\n",
    "        lens_record.append(len_stack)\n",
    "    print(\"The real max length of unfloded-sentence is: \", max_words)\n",
    "    print(\"The real length of first 10 sentences in train_set:\", lens_record[0][0:10])\n",
    "    return max_words,lens_record\n",
    "\n",
    "max_words,lens_record = tokenized_wordnums([sst2_train, sst2_test, sst2_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77efe446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67349, 1, 58, 50])\n"
     ]
    }
   ],
   "source": [
    "train_tensor = zip_st_pics(sst2_train, max_words, False).reshape(sst2_train.shape[0],max_words,50)\n",
    "test_tensor = zip_st_pics(sst2_test, max_words, False).reshape(sst2_test.shape[0],max_words,50)\n",
    "validation_tensor = zip_st_pics(sst2_validation, max_words, False).reshape(sst2_validation.shape[0],max_words,50)\n",
    "\n",
    "train_tensor = train_tensor.reshape(sst2_train.shape[0],1,max_words,50)\n",
    "test_tensor = test_tensor.reshape(sst2_test.shape[0],1,max_words,50)\n",
    "validation_tensor = validation_tensor.reshape(sst2_validation.shape[0],1,max_words,50)\n",
    "print(train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af8918a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1,  ..., 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "train_label = torch.tensor([sst2_train['label'][idx] for idx in sst2_train.index])\n",
    "validation_label = torch.tensor([sst2_validation['label'][idx] for idx in sst2_validation.index])\n",
    "pprint(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9f319",
   "metadata": {},
   "source": [
    "## Semantic Recognition in CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25eb8861",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6740306f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_tensor = train_tensor.reshape(sst2_train.shape[0],1,max_words,50)\\ntest_tensor = test_tensor.reshape(sst2_test.shape[0],1,max_words,50)\\nvalidation_tensor = validation_tensor.reshape(sst2_validation.shape[0],1,max_words,50)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to reshape again for another CNN training, you can run the following codes\n",
    "'''\n",
    "train_tensor = train_tensor.reshape(sst2_train.shape[0],1,max_words,50)\n",
    "test_tensor = test_tensor.reshape(sst2_test.shape[0],1,max_words,50)\n",
    "validation_tensor = validation_tensor.reshape(sst2_validation.shape[0],1,max_words,50)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f53fd14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemanticCNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 25), stride=(1, 5), padding=(1, 0))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 6), stride=(1, 1), padding=(1, 0))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=3)\n",
      "  (fc1): Linear(in_features=288, out_features=8, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc2): Linear(in_features=8, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SemanticCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SemanticCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,16, (3,25), (1,5), padding = (1,0))\n",
    "        self.conv2 = nn.Conv2d(16, 32, (3,6), 1, padding = (1,0))\n",
    "        self.flatten = nn.Flatten(1,3)\n",
    "        self.fc1 = nn.Linear(32*9*1, 8)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(8, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x, kernel_size=(3,1), stride=(3,1))\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x, kernel_size=(2,1), stride=(2,1))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        output = x\n",
    "        return output\n",
    "\n",
    "# 初始化模型\n",
    "model = SemanticCNN().to(device)\n",
    "print(model)\n",
    "\n",
    "# 选择合适的优化器\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08e4ead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "epoch:(1/5)\n",
      "(0/673) loss: 0.694923\n",
      "(100/673) loss: 0.560322\n",
      "(200/673) loss: 0.557908\n",
      "(300/673) loss: 0.510336\n",
      "(400/673) loss: 0.504134\n",
      "(500/673) loss: 0.454264\n",
      "(600/673) loss: 0.434851\n",
      "\n",
      "Test set: Average loss: 0.5368, Accuracy: 649/872 (74%)\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "epoch:(2/5)\n",
      "(0/673) loss: 0.506065\n",
      "(100/673) loss: 0.456608\n",
      "(200/673) loss: 0.470803\n",
      "(300/673) loss: 0.416812\n",
      "(400/673) loss: 0.492803\n",
      "(500/673) loss: 0.435320\n",
      "(600/673) loss: 0.401955\n",
      "\n",
      "Test set: Average loss: 0.5300, Accuracy: 676/872 (78%)\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "epoch:(3/5)\n",
      "(0/673) loss: 0.451557\n",
      "(100/673) loss: 0.422490\n",
      "(200/673) loss: 0.475034\n",
      "(300/673) loss: 0.404627\n",
      "(400/673) loss: 0.506154\n",
      "(500/673) loss: 0.415291\n",
      "(600/673) loss: 0.405774\n",
      "\n",
      "Test set: Average loss: 0.5378, Accuracy: 680/872 (78%)\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "epoch:(4/5)\n",
      "(0/673) loss: 0.441960\n",
      "(100/673) loss: 0.403207\n",
      "(200/673) loss: 0.453087\n",
      "(300/673) loss: 0.396068\n",
      "(400/673) loss: 0.485292\n",
      "(500/673) loss: 0.429780\n",
      "(600/673) loss: 0.464311\n",
      "\n",
      "Test set: Average loss: 0.5387, Accuracy: 674/872 (77%)\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "epoch:(5/5)\n",
      "(0/673) loss: 0.436926\n",
      "(100/673) loss: 0.393814\n",
      "(200/673) loss: 0.410310\n",
      "(300/673) loss: 0.416171\n",
      "(400/673) loss: 0.439072\n",
      "(500/673) loss: 0.395147\n",
      "(600/673) loss: 0.404902\n",
      "\n",
      "Test set: Average loss: 0.5298, Accuracy: 676/872 (78%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "\n",
    "def train_CNN(model, train_tensor, train_label, optimizer, epoch):\n",
    "    torch.manual_seed(1)\n",
    "    global max_epoch\n",
    "    global batch_size\n",
    "    print(\"epoch:(%d/%d)\" % (epoch, max_epoch))\n",
    "    model.train()\n",
    "    for batch_start in range(0, train_tensor.shape[0], batch_size):\n",
    "        data, target = train_tensor[batch_start:min(batch_start + batch_size,train_tensor.shape[0])],\\\n",
    "            train_label[batch_start:min(batch_start + batch_size,train_tensor.shape[0])]\n",
    "\n",
    "        # 清空之前轮次计算的梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播得到预测结果\n",
    "        output = model(data)\n",
    "\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_start/batch_size) % 100 == 0:\n",
    "            print('(%d/%d) loss: %f' % (batch_start/batch_size, (train_tensor.shape[0]//batch_size), loss.item()))\n",
    "\n",
    "def test_CNN(model, test_tensor, test_label):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data, target = test_tensor, test_label\n",
    "        output = model(data)\n",
    "        test_loss = loss_fn(output, target).item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, test_tensor.shape[0],\n",
    "        100. * correct / test_tensor.shape[0]))\n",
    "\n",
    "for epoch in range(1, max_epoch + 1):\n",
    "    print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "    train_CNN(model, train_tensor, train_label, optimizer, epoch)\n",
    "    test_CNN(model, validation_tensor, validation_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d46638",
   "metadata": {},
   "source": [
    "#### <font size = 4 face = \"Cambria Math\">an example to see why the loss is boosted while accuaracy is higher<font>\n",
    "    有一个样本预测输出是[0.1, 0.9], 它的交叉熵损失为loss = -1* log(0.9) = 0.046, 预测结果为：狗\n",
    "    另一个样本的预测输出是[0.4, 0.6], 它的交叉熵损失为loss = -1 * log(0.6) = 0.222, 预测结果为：狗\n",
    "    可以看出两个样本都预测的为狗，但是他们的交叉熵损失差别很大。因此我们在训练时，可能会出现准确率和交叉熵同时上升的情况。\n",
    "    ————————————————\n",
    "    版权声明：本文为CSDN博主「CVsaber」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\n",
    "<a href=\"https://blog.csdn.net/u014421797/article/details/104689384\" title=\"原文链接\">原文链接</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa943f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model_save/Semantic CNN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./model_save/Semantic CNN\"\n",
    "print(path)\n",
    "#保存\n",
    "torch.save(model.state_dict(), path)\n",
    "#读取\n",
    "CNN_model = SemanticCNN()\n",
    "CNN_model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50c2e321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        ...,\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "CNN_model.eval()\n",
    "test_output = CNN_model(test_tensor)\n",
    "test_pre_1 = test_output.argmax(dim=1, keepdim=True)\n",
    "validation_output = CNN_model(validation_tensor)\n",
    "validation_pre_1 = validation_output.argmax(dim=1, keepdim=True)\n",
    "pprint(test_pre_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f2a09a",
   "metadata": {},
   "source": [
    "## Pack Padded Data ---- The Class Used latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bff3bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = train_tensor.reshape(sst2_train.shape[0],max_words,50)\n",
    "test_tensor = test_tensor.reshape(sst2_test.shape[0],max_words,50)\n",
    "validation_tensor = validation_tensor.reshape(sst2_validation.shape[0],max_words,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "279960f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([[ 0.1319,  0.1627, -0.6191,  ...,  0.9364, -0.1538,  0.4060],\n",
      "        [ 0.3004,  0.2501, -0.1669,  ..., -0.0713,  0.2305, -0.5194],\n",
      "        [ 0.9619,  0.0125,  0.2173,  ...,  0.1403, -0.3847, -0.3871],\n",
      "        ...,\n",
      "        [ 0.2789, -0.1845,  0.8661,  ..., -0.1348, -0.3713,  0.7045],\n",
      "        [ 0.1516,  0.3018, -0.1676,  ..., -0.3565,  0.0164,  0.1022],\n",
      "        [-0.1643,  0.1572, -0.5502,  ...,  0.7434,  0.2357, -0.1369]]), batch_sizes=tensor([10, 10, 10,  9,  9,  9,  9,  9,  7,  5,  5,  4,  4,  3,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1]), sorted_indices=tensor([6, 4, 9, 2, 5, 3, 8, 0, 1, 7]), unsorted_indices=tensor([7, 8, 3, 5, 1, 4, 0, 9, 6, 2]))\n"
     ]
    }
   ],
   "source": [
    "example_batch = 10\n",
    "train_pk_sq = nn.utils.rnn.pack_padded_sequence(\n",
    "    input = train_tensor[0:example_batch],\n",
    "    lengths = lens_record[0][0:example_batch],\n",
    "    batch_first = True,\n",
    "    enforce_sorted = False,\n",
    ")\n",
    "pprint(train_pk_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06ed7408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def same_sort(origin, unsorted_indices):\n",
    "    new = origin.clone()\n",
    "    for i in range(len(unsorted_indices)):\n",
    "        new[i] = origin[unsorted_indices[i]]\n",
    "    return new\n",
    "\n",
    "new_label = same_sort(train_label[0:100],train_pk_sq.unsorted_indices)\n",
    "print(all(same_sort(new_label,train_pk_sq.sorted_indices) == train_label[0:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c7198",
   "metadata": {},
   "source": [
    "## Beter Sentiment Analysis in RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "749fcb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (rnn): GRU(50, 50, batch_first=True)\n",
      "  (cv): Conv1d(58, 12, kernel_size=(1,), stride=(1,))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=2)\n",
      "  (fc1): Linear(in_features=600, out_features=8, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc2): Linear(in_features=8, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.utils.rnn as rnn_F\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, seq_len, hidden_size):\n",
    "        super(SentimentRNN, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.rnn = nn.GRU(50, hidden_size ,batch_first = True)\n",
    "        self.cv = nn.Conv1d(seq_len, 12, 1, 1, 0)\n",
    "        self.flatten = nn.Flatten(1,2)\n",
    "        self.fc1 = nn.Linear(12*hidden_size, 8)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(8, 2)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        x = rnn_F.pack_padded_sequence(\n",
    "            input = x,\n",
    "            lengths = lengths,\n",
    "            batch_first = True,\n",
    "            enforce_sorted = False,\n",
    "        )\n",
    "        x,h = self.rnn(x)\n",
    "        x,relens = rnn_F.pad_packed_sequence(\n",
    "            x, \n",
    "            batch_first=True, \n",
    "            padding_value=0.0, \n",
    "            total_length=self.seq_len\n",
    "        )\n",
    "        \n",
    "        x = self.cv(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        output = x\n",
    "        return output,relens\n",
    "\n",
    "hidden_size = 50\n",
    "# 初始化模型\n",
    "model = SentimentRNN(max_words, hidden_size).to(device)\n",
    "print(model)\n",
    "\n",
    "# 选择合适的优化器\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8887f621",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "epoch:(1/5)\n",
      "(0/673) loss: 0.693300\n",
      "(100/673) loss: 0.528163\n",
      "(200/673) loss: 0.479871\n",
      "(300/673) loss: 0.491562\n",
      "(400/673) loss: 0.465680\n",
      "(500/673) loss: 0.468709\n",
      "(600/673) loss: 0.414829\n",
      "\n",
      "Test set: Average loss: 0.4765, Accuracy: 691/872 (79%)\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "epoch:(2/5)\n",
      "(0/673) loss: 0.407401\n",
      "(100/673) loss: 0.421536\n",
      "(200/673) loss: 0.365150\n",
      "(300/673) loss: 0.365971\n",
      "(400/673) loss: 0.406671\n",
      "(500/673) loss: 0.415008\n",
      "(600/673) loss: 0.320738\n",
      "\n",
      "Test set: Average loss: 0.5086, Accuracy: 705/872 (81%)\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "epoch:(3/5)\n",
      "(0/673) loss: 0.309583\n",
      "(100/673) loss: 0.349073\n",
      "(200/673) loss: 0.333274\n",
      "(300/673) loss: 0.274069\n",
      "(400/673) loss: 0.444856\n",
      "(500/673) loss: 0.360928\n",
      "(600/673) loss: 0.309115\n",
      "\n",
      "Test set: Average loss: 0.6250, Accuracy: 696/872 (80%)\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "epoch:(4/5)\n",
      "(0/673) loss: 0.283334\n",
      "(100/673) loss: 0.290959\n",
      "(200/673) loss: 0.311858\n",
      "(300/673) loss: 0.280024\n",
      "(400/673) loss: 0.423190\n",
      "(500/673) loss: 0.295785\n",
      "(600/673) loss: 0.272790\n",
      "\n",
      "Test set: Average loss: 0.7242, Accuracy: 689/872 (79%)\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "epoch:(5/5)\n",
      "(0/673) loss: 0.261781\n",
      "(100/673) loss: 0.259945\n",
      "(200/673) loss: 0.242624\n",
      "(300/673) loss: 0.251464\n",
      "(400/673) loss: 0.412807\n",
      "(500/673) loss: 0.286572\n",
      "(600/673) loss: 0.253282\n",
      "\n",
      "Test set: Average loss: 0.7618, Accuracy: 690/872 (79%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "\n",
    "def train_RNN(model, train_tensor, train_label, lens_record, optimizer, epoch):\n",
    "    torch.manual_seed(1)\n",
    "    global max_epoch\n",
    "    global batch_size\n",
    "    print(\"epoch:(%d/%d)\" % (epoch, max_epoch))\n",
    "    model.train()\n",
    "    for batch_start in range(0, train_tensor.shape[0], batch_size):\n",
    "        data, target = train_tensor[batch_start:min(batch_start + batch_size,train_tensor.shape[0])],\\\n",
    "            train_label[batch_start:min(batch_start + batch_size,train_tensor.shape[0])]\n",
    "        lengths = lens_record[batch_start:min(batch_start + batch_size,train_tensor.shape[0])]\n",
    "        \n",
    "        # 清空之前轮次计算的梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播得到预测结果\n",
    "        output,relens = model(data, lengths)\n",
    "        if any(relens != torch.tensor(lengths)):\n",
    "            raise Exception(\"Something may be wrong in the model forward function.\")\n",
    "\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_start/batch_size) % 100 == 0:\n",
    "            print('(%d/%d) loss: %f' % (batch_start/batch_size, (train_tensor.shape[0]//batch_size), loss.item()))\n",
    "\n",
    "def test_RNN(model, test_tensor, test_label, lens_record):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data, target = test_tensor, test_label\n",
    "        output, relens = model(data, lens_record)\n",
    "        test_loss = loss_fn(output, target).item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, test_tensor.shape[0],\n",
    "        100. * correct / test_tensor.shape[0]))\n",
    "\n",
    "for epoch in range(1, max_epoch + 1):\n",
    "    print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "    train_RNN(model, train_tensor, train_label, lens_record[0], optimizer, epoch)\n",
    "    test_RNN(model, validation_tensor, validation_label, lens_record[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1be7544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model_save/Sentiment RNN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./model_save/Sentiment RNN\"\n",
    "print(path)\n",
    "#保存\n",
    "torch.save(model.state_dict(), path)\n",
    "#读取\n",
    "RNN_model = SentimentRNN(max_words, hidden_size)\n",
    "RNN_model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0bcbe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7628])\n"
     ]
    }
   ],
   "source": [
    "RNN_model.eval()\n",
    "test_output, relens = RNN_model(test_tensor, lens_record[1])\n",
    "test_pre_2 = test_output.argmax(dim=1, keepdim=True)\n",
    "validation_output, relens = RNN_model(validation_tensor, lens_record[2])\n",
    "validation_pre_2 = validation_output.argmax(dim=1, keepdim=True)\n",
    "print(sum(test_pre_2 == test_pre_1)/max(test_pre_1.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e69a7",
   "metadata": {},
   "source": [
    "## The RNN with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4111ed11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionRNN(\n",
      "  (rnn): GRU(50, 50, batch_first=True)\n",
      "  (query): Linear(in_features=50, out_features=12, bias=True)\n",
      "  (key): Linear(in_features=50, out_features=12, bias=True)\n",
      "  (value): Linear(in_features=50, out_features=12, bias=True)\n",
      "  (multihead_attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=12, out_features=12, bias=True)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=2)\n",
      "  (fc): Linear(in_features=696, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class AttentionRNN(nn.Module):\n",
    "    def __init__(self, seq_len, hidden_size_1, hidde_size_2, num_heads):\n",
    "        super(AttentionRNN, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.rnn = nn.GRU(50, hidden_size_1 ,batch_first = True)\n",
    "        \n",
    "        self.query = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.key = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.value = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.multihead_attn = nn.MultiheadAttention(hidden_size_2, num_heads, dropout = 0.1, batch_first = True)\n",
    "        \n",
    "        self.flatten = nn.Flatten(1,2)\n",
    "        self.fc = nn.Linear(seq_len*hidden_size_2, 2)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        x = rnn_F.pack_padded_sequence(\n",
    "            input = x,\n",
    "            lengths = lengths,\n",
    "            batch_first = True,\n",
    "            enforce_sorted = False,\n",
    "        )\n",
    "        x,h = self.rnn(x)\n",
    "        x,relens = rnn_F.pad_packed_sequence(\n",
    "            x, \n",
    "            batch_first=True, \n",
    "            padding_value=0.0, \n",
    "            total_length=self.seq_len\n",
    "        )\n",
    "\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "        attn_output, attn_weights = self.multihead_attn(q, k, v)\n",
    "        x = attn_output\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        output = x\n",
    "        return output,relens\n",
    "\n",
    "hidden_size_1 = 50\n",
    "hidden_size_2 = 12\n",
    "num_heads = 12\n",
    "# 初始化模型\n",
    "model = AttentionRNN(max_words, hidden_size_1, hidden_size_2, num_heads).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e77d5df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "epoch:(1/6)\n",
      "(0/673) loss: 0.693457\n",
      "(100/673) loss: 0.587299\n",
      "(200/673) loss: 0.508048\n",
      "(300/673) loss: 0.416117\n",
      "(400/673) loss: 0.432609\n",
      "(500/673) loss: 0.374669\n",
      "(600/673) loss: 0.407036\n",
      "\n",
      "Test set: Average loss: 0.4639, Accuracy: 687/872 (79%)\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "epoch:(2/6)\n",
      "(0/673) loss: 0.413637\n",
      "(100/673) loss: 0.394494\n",
      "(200/673) loss: 0.402105\n",
      "(300/673) loss: 0.335213\n",
      "(400/673) loss: 0.356800\n",
      "(500/673) loss: 0.383554\n",
      "(600/673) loss: 0.338467\n",
      "\n",
      "Test set: Average loss: 0.4365, Accuracy: 699/872 (80%)\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "epoch:(3/6)\n",
      "(0/673) loss: 0.381640\n",
      "(100/673) loss: 0.344872\n",
      "(200/673) loss: 0.332941\n",
      "(300/673) loss: 0.278433\n",
      "(400/673) loss: 0.336814\n",
      "(500/673) loss: 0.394690\n",
      "(600/673) loss: 0.295970\n",
      "\n",
      "Test set: Average loss: 0.4355, Accuracy: 702/872 (81%)\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "epoch:(4/6)\n",
      "(0/673) loss: 0.356789\n",
      "(100/673) loss: 0.307147\n",
      "(200/673) loss: 0.285467\n",
      "(300/673) loss: 0.238465\n",
      "(400/673) loss: 0.312780\n",
      "(500/673) loss: 0.382484\n",
      "(600/673) loss: 0.259182\n",
      "\n",
      "Test set: Average loss: 0.4473, Accuracy: 706/872 (81%)\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "epoch:(5/6)\n",
      "(0/673) loss: 0.335851\n",
      "(100/673) loss: 0.269530\n",
      "(200/673) loss: 0.267653\n",
      "(300/673) loss: 0.211446\n",
      "(400/673) loss: 0.301730\n",
      "(500/673) loss: 0.362786\n",
      "(600/673) loss: 0.227983\n",
      "\n",
      "Test set: Average loss: 0.4490, Accuracy: 707/872 (81%)\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "epoch:(6/6)\n",
      "(0/673) loss: 0.310341\n",
      "(100/673) loss: 0.239444\n",
      "(200/673) loss: 0.246463\n",
      "(300/673) loss: 0.187612\n",
      "(400/673) loss: 0.296036\n",
      "(500/673) loss: 0.325415\n",
      "(600/673) loss: 0.201649\n",
      "\n",
      "Test set: Average loss: 0.4626, Accuracy: 713/872 (82%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 选择合适的优化器\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "max_epoch = 6\n",
    "batch_size = 100\n",
    "\n",
    "for epoch in range(1, max_epoch + 1):\n",
    "    print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "    train_RNN(model, train_tensor, train_label, lens_record[0], optimizer, epoch)\n",
    "    test_RNN(model, validation_tensor, validation_label, lens_record[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06f7b1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model_save/Attention RNN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./model_save/Attention RNN\"\n",
    "print(path)\n",
    "#保存\n",
    "torch.save(model.state_dict(), path)\n",
    "#读取\n",
    "attRNN_model = AttentionRNN(max_words, hidden_size_1, hidden_size_2, num_heads)\n",
    "attRNN_model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5b1f806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8204])\n",
      "tensor([0.8018])\n"
     ]
    }
   ],
   "source": [
    "attRNN_model.eval()\n",
    "test_output, relens = attRNN_model(test_tensor, lens_record[1])\n",
    "test_pre_3 = test_output.argmax(dim=1, keepdim=True)\n",
    "validation_output, relens = attRNN_model(validation_tensor, lens_record[2])\n",
    "validation_pre_3 = validation_output.argmax(dim=1, keepdim=True)\n",
    "print(sum(test_pre_3 == test_pre_2)/max(test_pre_2.shape))\n",
    "print(sum(test_pre_3 == test_pre_1)/max(test_pre_1.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c0463",
   "metadata": {},
   "source": [
    "## Conclusion and Implement on Given SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5172825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in combination of the validation result: 81.42%\n"
     ]
    }
   ],
   "source": [
    "validation_pre = (validation_pre_3 + validation_pre_2 + validation_pre_1) >= 2\n",
    "correct = validation_pre.eq(validation_label.view_as(validation_pre)).sum().item()\n",
    "print(\"Accuracy in combination of the validation result:\",\"{:.2%}\".format(correct / validation_tensor.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d24947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5014])\n",
      "                                               sentence  label\n",
      "idx                                                           \n",
      "0                uneasy mishmash of styles and genres .   True\n",
      "1     this film 's relationship to actual tension is...  False\n",
      "2     by the end of no such thing the audience , lik...   True\n",
      "3     director rob marshall went out gunning to make...   True\n",
      "4     lathan and diggs have considerable personal ch...   True\n",
      "...                                                 ...    ...\n",
      "1816  it risks seeming slow and pretentious , becaus...  False\n",
      "1817  take care of my cat offers a refreshingly diff...   True\n",
      "1818  davis has filled out his cast with appealing f...   True\n",
      "1819  it represents better-than-average movie-making...  False\n",
      "1820  dazzling and sugar-sweet , a blast of shallow ...   True\n",
      "\n",
      "[1821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_pre = (test_pre_3 + test_pre_2 + test_pre_1) >= 2\n",
    "print(sum(test_pre)/len(test_pre))\n",
    "sst2_test['label'] = test_pre\n",
    "pprint(sst2_test)\n",
    "sst2_test.to_csv(\"./sst2_original_test_result.csv\",sep=',',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cfd7739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               sentence  label\n",
      "0                                                  pig       0\n",
      "1     you watch them clumsily mugging their way thro...      0\n",
      "2                                      horrible poetry       0\n",
      "3                               exceeds expectations .       1\n",
      "4     beneath the film 's obvious determination to s...      1\n",
      "...                                                 ...    ...\n",
      "9995                                a fun family movie       1\n",
      "9996  has the rare capability to soothe and break yo...      1\n",
      "9997                                          is funny       1\n",
      "9998  political prisoners , poverty and the boat loa...      0\n",
      "9999  can be distinguished from a mediocre one by th...      1\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "given_tr = pd.read_csv(\"./sst2/情感分类数据集-sst-2/sst-2/train.csv\", low_memory = False)\n",
    "given_ts = pd.read_csv(\"./sst2/情感分类数据集-sst-2/sst-2/test.csv\", low_memory = False)\n",
    "pprint(given_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb393ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The real max length of unfloded-sentence is:  55\n",
      "The real length of first 10 sentences in train_set: [2, 11, 3, 4, 23, 21, 6, 11, 8, 25]\n"
     ]
    }
   ],
   "source": [
    "max_words2, lens_record2 = tokenized_wordnums([given_tr, given_ts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "502b187c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 58, 50])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "train_tensor2 = zip_st_pics(given_tr, max_words, False).reshape(given_tr.shape[0],max_words,50)\n",
    "test_tensor2 = zip_st_pics(given_ts, max_words, False).reshape(given_ts.shape[0],max_words,50)\n",
    "print(train_tensor2.shape)\n",
    "train_label2 = torch.tensor([given_tr['label'][idx] for idx in given_tr.index])\n",
    "print(train_label2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e5f50",
   "metadata": {},
   "source": [
    "#### <font size = 4 face = \"Cambria Math\">PS: 如果在给出数据集上表现不好, 再进一步训练<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44c750f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8667])\n",
      "tensor([0.9153])\n",
      "tensor([0.8710])\n"
     ]
    }
   ],
   "source": [
    "CNN_model.eval()\n",
    "train_output = CNN_model(train_tensor2.reshape(given_tr.shape[0],1,max_words,50))\n",
    "train_pre_1 = train_output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "RNN_model.eval()\n",
    "train_output, relens = RNN_model(train_tensor2, lens_record2[0])\n",
    "train_pre_2 = train_output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "attRNN_model.eval()\n",
    "train_output, relens = attRNN_model(train_tensor2, lens_record2[0])\n",
    "train_pre_3 = train_output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "print(sum(train_pre_2 == train_pre_1)/max(train_pre_1.shape))\n",
    "print(sum(train_pre_3 == train_pre_2)/max(train_pre_2.shape))\n",
    "print(sum(train_pre_3 == train_pre_1)/max(train_pre_1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32f78c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in combination of the new train result: 90.39%\n"
     ]
    }
   ],
   "source": [
    "train_pre = (train_pre_3 + train_pre_2 + train_pre_1) >= 2\n",
    "correct = train_pre.eq(train_label2.view_as(train_pre)).sum().item()\n",
    "print(\"Accuracy in combination of the new train result:\",\"{:.2%}\".format(correct / train_tensor2.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230fb570",
   "metadata": {},
   "source": [
    "#### <font size = 4 face = \"Cambria Math\">我们再回过头来对比一下被使用的训练集(loaded - not given sst2)上的准确率<font>  \n",
    "不建议在普通电脑上使用原数据全集(含60000多条数据), 这会导致内存溢出错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3416199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8677])\n",
      "tensor([0.9085])\n",
      "tensor([0.8672])\n"
     ]
    }
   ],
   "source": [
    "CNN_model.eval()\n",
    "train_output = CNN_model(train_tensor[0:10000].reshape(10000,1,max_words,50))\n",
    "train_pre_1 = train_output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "RNN_model.eval()\n",
    "train_output, relens = RNN_model(train_tensor[0:10000], lens_record[0][0:10000])\n",
    "train_pre_2 = train_output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "attRNN_model.eval()\n",
    "train_output, relens = attRNN_model(train_tensor[0:10000], lens_record[0][0:10000])\n",
    "train_pre_3 = train_output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "print(sum(train_pre_2 == train_pre_1)/max(train_pre_1.shape))\n",
    "print(sum(train_pre_3 == train_pre_2)/max(train_pre_2.shape))\n",
    "print(sum(train_pre_3 == train_pre_1)/max(train_pre_1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e33687c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in combination of the original train result: 90.00%\n"
     ]
    }
   ],
   "source": [
    "train_pre = (train_pre_3 + train_pre_2 + train_pre_1) >= 2\n",
    "correct = train_pre.eq(train_label[0:10000].view_as(train_pre)).sum().item()\n",
    "print(\"Accuracy in combination of the original train result:\",\"{:.2%}\".format(correct / 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8dd88d",
   "metadata": {},
   "source": [
    "#### <font size = 4 face = \"Cambria Math\">由于新旧数据集的准确率非常相近 --- 不必进一步训练<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31a8d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.eval()\n",
    "test_output = CNN_model(test_tensor2.reshape(given_ts.shape[0],1,max_words,50))\n",
    "test_pre_1 = test_output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "RNN_model.eval()\n",
    "test_output, relens = RNN_model(test_tensor2, lens_record2[1])\n",
    "test_pre_2 = test_output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "attRNN_model.eval()\n",
    "test_output, relens = attRNN_model(test_tensor2, lens_record2[1])\n",
    "test_pre_3 = test_output.argmax(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7295e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5540])\n",
      "                                              sentence  label\n",
      "0                                         meaningless   False\n",
      "1        solid , kinetically-charged spy flick worthy    True\n",
      "2                                           strongest    True\n",
      "3      do cliches , no matter how ` inside ' they are   False\n",
      "4                       cleverly constructed scenario    True\n",
      "..                                                 ...    ...\n",
      "995                     jaw-droppingly beautiful work    True\n",
      "996                  funny , ultimately heartbreaking    True\n",
      "997  it 's been 13 months and 295 preview screening...  False\n",
      "998  the art of getting laid in this prickly indie ...   True\n",
      "999  ( seagal 's ) strenuous attempt at a change in...  False\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_pre = (test_pre_3 + test_pre_2 + test_pre_1) >= 2\n",
    "print(sum(test_pre)/len(test_pre))\n",
    "given_ts['label'] = test_pre\n",
    "pprint(given_ts)\n",
    "given_ts.to_csv(\"./SA_test_result.csv\",sep=',',index=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8453c3f",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc800e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "原始单元格格式",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
